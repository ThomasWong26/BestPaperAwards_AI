# Best Paper Awards in Top Conferences of Artificial Intelligence

## Conference on Computer Vision and Pattern Recognition (CVPR)
[2025](https://cvpr.thecvf.com/Conferences/2025/BestPapersDemos), [2024]

### Best Paper
(2025) [VGGT: Visual Geometry Grounded Transformer](https://openaccess.thecvf.com/content/CVPR2025/papers/Wang_VGGT_Visual_Geometry_Grounded_Transformer_CVPR_2025_paper.pdf), [Code](https://github.com/facebookresearch/vggt), [Supplementary](https://openaccess.thecvf.com/content/CVPR2025/supplemental/Wang_VGGT_Visual_Geometry_CVPR_2025_supplemental.pdf) **Authors**: Jianyuan Wang, Minghao Chen, Nikita Karaev, Andrea Vedaldi, Christian Rupprecht, David Novotny. **Affiliations**: University of Oxford, Meta AI

### Best Student Paper
(2025) [VGGT: Visual Geometry Grounded Transformer](https://openaccess.thecvf.com/content/CVPR2025/papers/Wang_VGGT_Visual_Geometry_Grounded_Transformer_CVPR_2025_paper.pdf), [Code](https://github.com/facebookresearch/vggt), [Supplementary](https://openaccess.thecvf.com/content/CVPR2025/supplemental/Wang_VGGT_Visual_Geometry_CVPR_2025_supplemental.pdf) **Authors**: Anagh Malik, Benjamin Attal, Andrew Xie, Matthew O'Toole, David B. Lindell. **Affiliations**: Visual Geometry Group, University of Oxford, Meta AI

### Best Paper Honorable Mention
(2025) [MegaSaM: Accurate, Fast and Robust Structure and Motion from Casual Dynamic Videos](https://openaccess.thecvf.com/content/CVPR2025/papers/Li_MegaSaM_Accurate_Fast_and_Robust_Structure_and_Motion_from_Casual_CVPR_2025_paper.pdf), [Code](https://github.com/mega-sam/mega-sam), [Supplementary](https://openaccess.thecvf.com/content/CVPR2025/supplemental/Li_MegaSaM_Accurate_Fast_CVPR_2025_supplemental.pdf) **Authors**: Zhengqi Li, Richard Tucker, Forrester Cole, Qianqian Wang, Linyi Jin, Vickie Ye, Angjoo Kanazawa, Aleksander Holynski, Noah Snavely. **Affiliations**: Google DeepMind, UC Berkeley, University of Michigan

(2025) [Navigation World Models](https://openaccess.thecvf.com/content/CVPR2025/papers/Bar_Navigation_World_Models_CVPR_2025_paper.pdf), [Code](https://github.com/facebookresearch/nwm), [Supplementary](https://openaccess.thecvf.com/content/CVPR2025/supplemental/Bar_Navigation_World_Models_CVPR_2025_supplemental.pdf) **Authors**: Amir Bar, Gaoyue Zhou, Danny Tran, Trevor Darrell, Yann LeCun. Affiliations: FAIR at Meta, New York University, Berkeley AI Research

(2025) [Molmo and PixMo: Open Weights and Open Data for State-of-the-Art Vision-Language Models](https://openaccess.thecvf.com/content/CVPR2025/papers/Deitke_Molmo_and_PixMo_Open_Weights_and_Open_Data_for_State-of-the-Art_CVPR_2025_paper.pdf), [Code](), [Supplementary](https://openaccess.thecvf.com/content/CVPR2025/supplemental/Deitke_Molmo_and_PixMo_CVPR_2025_supplemental.pdf) **Authors**: Matt Deitke, Christopher Clark, Sangho Lee, Rohun Tripathi, Yue Yang, Jae Sung Park, Mohammadreza Salehi, Niklas Muennighoff, Kyle Lo, Luca Soldaini, Jiasen Lu, Taira Anderson, Erin Bransom, Kiana Ehsani, Huong Ngo, YenSung Chen, Ajay Patel, Mark Yatskar, Chris Callison-Burch, Andrew Head, Rose Hendrix, Favyen Bastani, Eli VanderBilt, Nathan Lambert, Yvonne Chou, Arnavi Chheda, Jenna Sparks, Sam Skjonsberg, Michael Schmitz, Aaron Sarnat, Byron Bischoff, Pete Walsh, Chris Newell, Piper Wolters, Tanmay Gupta, Kuo-Hao Zeng, Jon Borchardt, Dirk Groeneveld, Crystal Nam, Sophie Lebrecht, Caitlin Wittlif, Carissa Schoenick, Oscar Michel, Ranjay Krishna, Luca Weihs, Noah A. Smith, Hannaneh Hajishirzi, Ross Girshick, Ali Farhadi, Aniruddha Kembhavi. **Affiliations**: Allen Institute for AI, University of Washington, University of Pennsylvania

(2025) [3D Student Splatting and Scooping](https://openaccess.thecvf.com/content/CVPR2025/papers/Zhu_3D_Student_Splatting_and_Scooping_CVPR_2025_paper.pdf), [Code](https://github.com/realcrane/3D-student-splatting-and-scooping), [Supplementary](https://openaccess.thecvf.com/content/CVPR2025/supplemental/Zhu_3D_Student_Splatting_CVPR_2025_supplemental.pdf) **Authors**: Jialin Zhu, Jiangbei Yue, Feixiang He, He Wang. **Affiliations**: University College London, UK, University of Leeds, UK, AI Centre, University College London, UK

### Best Student Paper Honorable Mention
(2025) [Generative Multimodal Pretraining with Discrete Diffusion Timestep Tokens](https://openaccess.thecvf.com/content/CVPR2025/papers/Pan_Generative_Multimodal_Pretraining_with_Discrete_Diffusion_Timestep_Tokens_CVPR_2025_paper.pdf), [Code](https://github.com/selftok-team/SelftokTokenizer/), [Supplementary](https://openaccess.thecvf.com/content/CVPR2025/supplemental/Pan_Generative_Multimodal_Pretraining_CVPR_2025_supplemental.pdf) **Authors**: Kaihang Pan, Wang Lin, Zhongqi Yue, Tenglong Ao, Liyu Jia, Wei Zhao, Juncheng Li, Siliang Tang, Hanwang Zhang. **Affiliations**: Zhejiang University, Nanyang Technological University, Peking University, Huawei Singapore Research Center

## International Conference on Computer Vision (ICCV)

## European Conference on Computer Vision (ECCV)

## Conference on Neural Information Processing Systems (NeurIPS)

## International Conference on Machine Learning (ICML)

## AAAI Conference on Artificial Intelligence (AAAI)

## International Conference on Learning Representations (ICLR)

## ACM Multimedia

## SIGGRAPH

## SIGGRAPH Asia
